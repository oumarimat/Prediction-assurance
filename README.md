# ğŸ©º PrÃ©diction des Frais d'Assurance SantÃ© avec InterprÃ©tation des ModÃ¨les

Dans ce projet, nous construisons un **modÃ¨le de machine learning prÃ©dictif** afin dâ€™estimer les *frais dâ€™assurance santÃ©* Ã  partir de donnÃ©es clients (Ã¢ge, sexe, IMC, nombre dâ€™enfants, statut fumeur, rÃ©gion). Lâ€™objectif est de simuler le travail dâ€™un data scientist dans une compagnie dâ€™assurance : prÃ©dire les coÃ»ts mÃ©dicaux futurs pour mieux tarifer, gÃ©rer les risques et personnaliser les offres.

## ğŸ›  Ã‰tapes du projet

Ce notebook suit une approche complÃ¨te et structurÃ©e :

1. **Exploration des donnÃ©es (EDA)** : comprendre les distributions, corrÃ©lations, et particularitÃ©s des variables.
2. **PrÃ©traitement** : encodage binaire (`sex`, `smoker`), One-Hot Encoding (`region`), ajout de variables dâ€™interaction (`age_smoker`, `bmi_sex`).
3. **ModÃ©lisation** :
   - ModÃ¨le de base : `RandomForestRegressor` (bon benchmark)
   - ModÃ¨le avancÃ© : `XGBoostRegressor` avec `GridSearchCV`, rÃ©gularisation (`reg_alpha`, `reg_lambda`) et validation croisÃ©e
4. **Ã‰valuation** :
   - Indicateurs utilisÃ©s : RÂ², MSE, MAE
   - Analyse des performances par segments (fumeur vs non-fumeur, sexe, rÃ©gions)
5. **InterprÃ©tabilitÃ© des modÃ¨les** :
   - âœ… **Importance globale** des variables (XGBoost `plot_importance`)
   - âœ… **SHAP** pour une interprÃ©tation *globale* (impact de chaque variable sur toutes les prÃ©dictions)
   - âœ… **SHAP** pour une interprÃ©tation *locale* (explication prÃ©cise dâ€™un individu)
   - âœ… **LIME** pour visualiser les rÃ¨gles locales qui influencent chaque prÃ©diction

---

## ğŸ¯ RÃ©sultats principaux

- Le modÃ¨le XGBoost atteint un **RÂ² de 0.88** et une **MAE de ~2459**, ce qui est performant pour un problÃ¨me de rÃ©gression sur donnÃ©es rÃ©elles.
- Les variables les plus importantes sont : `smoker`, `bmi`, `age`, et les interactions (`age_smoker`, `bmi_sex`).
- Des biais dâ€™erreur ont Ã©tÃ© identifiÃ©s : les prÃ©dictions sont lÃ©gÃ¨rement moins prÃ©cises pour les hommes et les fumeurs.

---

## ğŸ” InterprÃ©tabilitÃ© : SHAP & LIME

Nous avons mis l'accent sur lâ€™explicabilitÃ© du modÃ¨le :

- **SHAP (SHapley Additive exPlanations)** fournit une interprÃ©tation fine et mathÃ©matiquement solide du modÃ¨le. Il permet de :
  - Visualiser lâ€™influence moyenne de chaque variable (`summary_plot`)
  - Comprendre pourquoi un individu reÃ§oit une certaine prÃ©diction (`waterfall_plot`)

- **LIME (Local Interpretable Model-Agnostic Explanations)** explique les prÃ©dictions ponctuelles en simulant un modÃ¨le local simple autour dâ€™une observation. Cela donne des rÃ¨gles lisibles comme :

  > "Le client n'est pas fumeur, a un IMC normal, et a entre 39 et 51 ans â†’ donc ses frais estimÃ©s sont faibles."

Ces outils permettent Ã  un acteur mÃ©tier (ex. un assureur) de **comprendre, faire confiance et justifier** le modÃ¨le.

---

## ğŸ§  Conclusion

Ce projet montre non seulement comment construire un modÃ¨le prÃ©dictif performant pour estimer des coÃ»ts dâ€™assurance santÃ©, mais aussi comment lâ€™**expliquer en toute transparence** grÃ¢ce Ã  SHAP et LIME.

Lâ€™interprÃ©tabilitÃ© est essentielle dans les secteurs rÃ©glementÃ©s comme lâ€™assurance, oÃ¹ les dÃ©cisions algorithmiques doivent Ãªtre comprÃ©hensibles par les clients, les actuaires et les rÃ©gulateurs.

ğŸ“Œ N'hÃ©sitez pas Ã  explorer les visualisations SHAP et LIME ci-dessous pour comprendre *comment et pourquoi* chaque prÃ©diction est faite.
